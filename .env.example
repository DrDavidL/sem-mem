# Sem-Mem Configuration
# Copy this file to .env and fill in your values
# NEVER commit .env to version control

# =============================================================================
# Provider Selection
# =============================================================================
# Chat and embedding providers can be different (e.g., Claude for chat, OpenAI for embeddings)

# Chat provider: openai (default), azure, anthropic, google, ollama, openrouter
SEMMEM_CHAT_PROVIDER=openai

# Embedding provider: openai (default), azure, google, ollama
# WARNING: Once set and used, cannot be changed without deleting/migrating the index
SEMMEM_EMBEDDING_PROVIDER=openai

# =============================================================================
# Provider API Keys (set the ones you need)
# =============================================================================

# OpenAI (Tier 1) - Required for openai provider
OPENAI_API_KEY=sk-your-key-here

# Azure OpenAI (Tier 1) - Required for azure provider
# AZURE_OPENAI_KEY=your-azure-key-here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-01

# Anthropic/Claude (Tier 2) - Required for anthropic provider
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Google/Gemini (Tier 2) - Required for google provider
# GOOGLE_API_KEY=your-google-key-here

# Ollama (Tier 2) - No API key required, just the base URL
# OLLAMA_BASE_URL=http://localhost:11434

# OpenRouter (Tier 3) - Required for openrouter provider
# OPENROUTER_API_KEY=sk-or-your-key-here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# Model Configuration
# =============================================================================

# Chat model (provider-specific)
# OpenAI: gpt-5.1, gpt-4.1, gpt-4.1-mini
# Azure: your-deployment-name
# Anthropic: claude-sonnet-4-20250514, claude-3-7-sonnet-20250219
# Google: gemini-2.0-flash, gemini-1.5-pro
# Ollama: llama3.2, mistral, codellama
# OpenRouter: anthropic/claude-3-opus, openai/gpt-4
SEMMEM_CHAT_MODEL=gpt-5.1

# Embedding model (provider-specific)
# OpenAI/Azure: text-embedding-3-small (1536d), text-embedding-3-large (3072d)
# Google: text-embedding-004 (768d)
# Ollama: nomic-embed-text (768d), mxbai-embed-large (1024d)
SEMMEM_EMBEDDING_MODEL=text-embedding-3-small

# Reasoning effort for reasoning models (low, medium, high)
REASONING_EFFORT=low

# =============================================================================
# Storage Configuration
# =============================================================================

# Memory storage directory (default: ./local_memory)
MEMORY_STORAGE_DIR=./local_memory

# L1 cache size (default: 20)
CACHE_SIZE=20

# =============================================================================
# Web Search
# =============================================================================
# Multiple backends supported. Priority (auto-detect): Exa > Google PSE > OpenAI
# Set WEB_SEARCH_BACKEND to force a specific one.

# --- Exa (recommended for real-time data) ---
# AI-native search with structured results. Great for weather, stocks, news.
# Get your API key from: https://exa.ai
# EXA_API_KEY=your-exa-api-key

# --- Google PSE ---
# Get your API key from: https://console.cloud.google.com/apis/credentials
# Create a search engine at: https://programmablesearchengine.google.com/
# GOOGLE_PSE_API_KEY=your-google-api-key
# GOOGLE_PSE_ENGINE_ID=your-engine-id

# Force a specific backend: "exa", "google_pse", or "openai" (auto-detect if not set)
# WEB_SEARCH_BACKEND=exa

# =============================================================================
# API Server (for client apps using FastAPI server)
# =============================================================================

# API server URL (default: http://localhost:8000)
SEMMEM_API_URL=http://localhost:8000
